# Query 1
big data developers

{
  "@odata.context": "https://hr-materials-cogsearch.search.windows.net/indexes('azuretable-index')/$metadata#docs(*)",
  "value": [
    {
      "@search.score": 3.0374863,
      "PartitionKey": "ms-learn",
      "Timestamp": "2022-05-13T02:11:08.567Z",
      "Key": "ms-learn0eb748ef-3b3f-447f-8f18-08f702165f4c",
      "duration": 37,
      "instructor": "",
      "level": "advanced",
      "product": "azure-active-directory",
      "rating_average": 4.67,
      "rating_count": 27,
      "role": "developer",
      "source": "MS Learn",
      "title": "Secure Cognitive Services",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.0374863,
      "PartitionKey": "ms-learn",
      "Timestamp": "2022-05-13T02:11:06.117Z",
      "Key": "ms-learn1edca8f0-0399-4f3b-8cb3-dcb9221199cf",
      "duration": 37,
      "instructor": "",
      "level": "advanced",
      "product": "azure-cognitive-services",
      "rating_average": 4.67,
      "rating_count": 27,
      "role": "administrator",
      "source": "MS Learn",
      "title": "Secure Cognitive Services",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    ...
  ],
  "@odata.nextLink": "https://hr-materials-cogsearch.search.windows.net/indexes('azuretable-index')/docs?api-version=2021-04-30-Preview&search=cognitive%20science&$skip=50"
}

# Query 2
https://<COGSEARCH_NAME>.search.windows.net/indexes/azureblob-index/docs?api-version=2021-04-30-Preview&search=distributed%20systems

{
    "@odata.context": "https://hr-materials-cogsearch.search.windows.net/indexes('azureblob-index')/$metadata#docs(*)",
    "value": [
      {
        "@search.score": 6.2522454,
        "content": "\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 \nDOI 10.1186/s40493-015-0019-z\n\nRESEARCH Open Access\n\nToward a testbed for evaluating\ncomputational trust models: experiments\nand analysis\nPartheeban Chandrasekaran and Babak Esfandiari*\n\n*Correspondence:\nbabak@sce.carleton.ca\nDepartment of Systems and\nComputer Engineering, Carleton\nUniversity, 1125 Colonel By Drive,\nOttawa, Ontario K1s5B6, Canada\n\nAbstract\nWe propose a generic testbed for evaluating social trust models and we show how\nexisting models can fit our tesbed. To showcase the flexibility of our design, we\nimplemented a prototype and evaluated three trust algorithms, namely EigenTrust,\nPeerTrust and Appleseed, for their vulnerabilites to attacks and compliance to various\ntrust properties. For example, we were able to exhibit discrepancies between\nEigenTrust and PeerTrust, as well as trade-offs between resistance to slandering attacks\nversus self-promotion.\n\nKeywords: Trust testbed; Reputation; Multi-agent systems\n\nIntroduction\nMotivation\n\nWith the growth of online community-based systems such as peer-to-peer file-sharing\napplications, e-commerce and social networking websites, there is an increasing need to\nprovide computational trust mechanisms to determine which users or agents are honest\nand which ones are malicious. Many models calculate trust by relying on analyzing a\nhistory of interactions. The calculations can range from the simple averaging of ratings\non eBay to flow-based scores in the Advogato website. Thus for a researcher to evaluate\nand compare his or her latest model against existing ones, a comprehensive test tool is\nneeded. However, our research shows that the tools that exist to assist researchers are not\nflexible enough to include different trust models and their evaluations. Moreover, these\ntools use their own set of application-dependent metrics to evaluate a reputation system.\nThis means that a number of trust models cannot be evaluated for vulnerabilities against\ncertain types of attacks. Thus, there is still a need for a generic testbed to evaluate and\ncompare computational trust models.\n\nOverview of our solution and contributions\n\nIn this paper, we present a model and a testbed for evaluating a family of trust algo-\nrithms that rely on past transactions between agents. Trust assessment is viewed as a\nprocess consisting of a succession of graph transformations, where the agents form the\nvertices of the graph. The meaning of the edges depends on the transformation stage,\n\n© 2015 Chandrasekaran and Esfandiari. Open Access This article is distributed under the terms of the Creative Commons\nAttribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution,\nand reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to\nthe Creative Commons license, and indicate if changes were made.\n\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40493-015-0019-z-x&domain=pdf\nmailto: babak@sce.carleton.ca\nhttp://creativecommons.org/licenses/by/4.0/\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 2 of 27\n\nand can refer to the presence of transactions between the two agents or the existence\nof a trust relationship between them. Our first contribution is to show that with this\nview, existing reputation systems can be adopted under a single model, but they work at\ndifferent stages of the trust assessment workflow. This allows us to present a new classi-\nfication scheme for a number of trust models based on where they fit in the assessment\nworkflow. The second contribution of our work is that this workflow can be described\nformally, and by doing this, we show that it is possible to model a variety of attacks\nand evaluation schemes. Finally, out of the larger number of systems we classified, we\nselected three reputation systems, namely EigenTrust [1], PeerTrust [2] and Appleseed\n[3], to exemplify the range and variety of reputation systems that our testbed can accom-\nmodate. We evaluated these three systems in our testbed against simple attacks and\nwe validated their compliance to basic trust properties. In particular, we were able to\nexhibit differences in the way EigenTrust and PeerTrust rank the agents, we observed\nthe subtle interplay between slandering and self-promoting attacks (higher sensitivity\nto one attack can lead to lower sensitivity to the other), and we verified that trust\nweakens along a friend-of-a-friend chain and that it is more easily lost than gained\n(as it should be).\n\nOrganization\n\nThis article is organized as follows: section ‘Background and literature review’ provides\nbackground and state of the art on trust models, attacks against them, and existing\ntestbeds for evaluation. Section ‘Problem description and model’ formulates the research\nproblem of this article and proposes our model for a testbed. Section ‘Classifying and\nchaining algorithms’ shows how some of existing trust algorithms can fit our model, and\nhow one can combine or compare them using our model and testbed. Section ‘Results and\ndiscussion’ describes the implementation details of our testbed prototype and presents\nevaluation results of three different trust algorithms, namely EigenTrust, PeerTrust, and\nAppleseed. Section ‘Conclusions’ concludes this article and summarizes the contributions\nand limitations of our work.\n\nBackground and literature review\nSocial trust models\n\nTrust management systems aid agents in establishing and assessing mutual trust. How-\never, the actual mechanisms used in these systems vary. For example, public key infras-\ntructures [4] rely on certificates whereas reputation-based trust management systems are\nbased on experiences of earlier direct and indirect interactions [5].\nIn this paper we will focus on social trust models based on reputation. The trust model\n\nshould provide a means to compare the trustworthiness of agents in order to choose a\nparticular agent to perform an action. For instance, on an e-commerce website like eBay,\nwe need to be able to compare the trustworthiness of sellers in order to pick the most\ntrustworthy one to buy a product from.\nSocial trust models rely on past experiences of agents to produce trust assertions. That\n\nis, the agents in the system interact with each other and record their experiences, which\nare then used to determine whether a particular agent is trustworthy. This model is self-\nsufficient because it does not rely on a third party to propagate trust, like it would in\ncertificate authority-based PKI trust models. However, there are drawbacks to having no\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 3 of 27\n\nroot of trust. For instance, agents evaluating the trustworthiness of agents with whom\nthere has been no interaction must use recommendations from others and, in turn,\nevaluate the trustworthiness of the recommenders. Social trust models must address this\nproblem.\n\nNature of input\n\nVarious inputs are used by social trust algorithms to measure the trustworthiness of\nagents. In EigenTrust [1], PeerTrust [2], TRAVOS [6] and Beta Reputation System (BRS)\n[7], agents rate their satisfaction after a transaction (e.g., downloading a file in a P2P\nfile-sharing network). These ratings are used to obtain a trust score that represents the\ntrustworthiness of the agent. In Aberer and Despotovic’s system [5]1, agents may file com-\nplaints (can be seen as dissatisfaction) about each other after a transaction. In Advogato\n[8], whose goal is to discourage spam on its blogging website, users explicitly certify\neach other as belonging to a particular level in the community. Trust algorithms may\nalso directly use trust scores among agents to compute an aggregated trustworthiness\nof agents, as in TidalTrust [9] and Appleseed [3]. In the specific context of P2P file-\nsharing, Credence [10] uses the votes on file authenticity to calculate a similarity score\nbetween agents and uses it to measure trust. The trust score is then used to recommend\nfiles.\n\nDirect vs. indirect trust\n\nThe truster may use some or all of its own and other agents’ past experiences with the\ntrustee to obtain a trust score. Trust algorithms often use gossiping to poll agents with\nwhom the truster has had interactions in the past.\nThe trust score calculated using only the experiences from direct interactions is\n\ncalled the direct trust score, while the trust score calculated using the recommenda-\ntions from other agents is called the indirect trust score [11]. As mentioned earlier,\nreputation systems use different inputs (satisfaction ratings, votes, certificates, etc.) to\ncalculate direct trust scores and indirect trust scores. PeerTrust uses satisfaction ratings\nto calculate both direct and indirect trust scores, whereas EigenTrust and TRAVOS\nuse satisfaction ratings to calculate direct trust scores, which they then use to calcu-\nlate indirect trust scores. Therefore, we can categorize the trust algorithms based on\nthe input required. But how do trust algorithms calculate the trust scores of agents\nusing the above information? It again varies from algorithm to algorithm. For instance,\nPeerTrust, EigenTrust, and Aberer use simple averaging of ratings, TRAVOS and BRS\nuse the beta probability density function, and Appleseed uses the Spreading Activation\nmodel.\n\nGlobal vs. local trust\n\nThe trust algorithm may output a global trust score or a local trust score [3, 12]. A global\ntrust score is one that represents the general trust that all agents have on a particular\nagent, whereas local trust scores represents the trust from the perspective of the truster\nand thus each truster may trust an agent differently. In our survey, we found PeerTrust,\nEigenTrust, and Aberer to be global trust algorithms whereas TRAVOS, BRS, Credence,\nAdvogato, TidalTrust, Appleseed, Marsh [13] and Abdul-Rahman [14] are local trust\nalgorithms.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 4 of 27\n\nTo trust or not to trust\n\nOnce the trust score is calculated, it can be used to decide whether to trust the agent. It\ncan be as simple as comparing the trust score against a threshold: if the trust score is above\na certain threshold, then the agent is trusted. Marsh [13], and Aberer [5] use thresholding\ntechniques. If the trust algorithm outputs normalized trust scores of agents as in Eigen-\nTrust, then the trust scores of agents are ranked. In this case, one may consider a certain\npercentage of the top ranked agents as trustworthy. In Appleseed, a graph is first obtained\nwith trust scores of agents as edge weights, and then, the truster agent is “injected” with\na value called the activation energy. This energy is spread to agents with a spreading fac-\ntor along the edges in the graph and the algorithm ranks the agents according to their\ntrust scores. Trust decisions can also be flow-based such as in Advogato, which calculates\na maximum “flow of trust” in the trust graph to determine which agents are trustworthy\nand which are not.\nIn short, social trust models focus on the following:\n\n1. What is the input to calculate the trust score of an agent?\n2. Does the trust algorithm use only direct experience or does it also rely on third\n\nparty recommendations?\n3. Is the trust score of an agent global or local?\n4. How does one decide whether to trust an agent?\n\nGiven the above discussion, and to assess the scope of our testbed, we propose to model,\nevaluate and compare three algorithms from fairly different families. The next sections\nprovide detailed descriptions of the trust models we selected and that we implemented in\nour testbed. The details are given to help understand the output of our experiments, but\nreaders familiar with EigenTrust, PeerTrust and/or AppleSeed may skip those respective\nsections.\n\nPeerTrust\n\nIn PeerTrust, agents rate each other in terms of the satisfaction received. These ratings\nare weighted by trust scores of the raters, and a global trust score is computed recursively\nusing Eq. 2.1, where:\n\n• T(u) is the trust score of agent u\n• I(u) is the set of transactions that agent u had with all the agents in the system\n• S(u, i) is the satisfaction rating on u for transaction i\n• p(u, i) is the agent that provided the rating.\n\nT(u) =\nI(u)∑\ni=1\n\nS(u, i) × T(p(u, i))∑I(u)\nj=1 T(p(u, j))\n\n(2.1)\n\nPeerTrust also provides a method for calculating local trust scores. In both local and\nglobal trust score computations, the trust score is compared against a threshold to decide\nwhether to trust or not.\n\nEigenTrust\n\nAgents in EigenTrust rate transactions as satisfactory or unsatisfactory [1]. These trans-\naction ratings are used as input, to calculate a local direct trust score, from which a global\ntrust score is then calculated.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 5 of 27\n\nAn agent i calculates the normalized local trust score of agent j, as shown in Eq. 2.2,\nwhere tij ∈ {+1, −1} is the transaction rating, and sij is the sum of ratings.\n\nsij =\n∑\nTij\n\ntrij\n\ncij =\nmax(sij, 0)∑\nk max(sik, 0)\n\n(2.2)\n\nNote that we cannot use sij as the local trust score without normalizing, because mali-\ncious agents can arbitrarily assign high local trust values to fellow malicious agents and\nlow local trust values to honest agents.\nTo calculate the global trust score of an agent, the truster queries his friends for their\n\ntrust scores on the trustee. These local trust scores are aggregated, as shown in Eq. 2.3.\n\ntik =\n∑\nj\ncijcjk (2.3)\n\nIf we let C be the matrix containing cij elements, �ci be the local trust vector for i (each\nelement corresponds to the trust that i has in j), and �ti the vector containing tik, then,\n\n�ti = CT �ci (2.4)\n\nBy asking a friend’s friend’s opinion, Eq. 2.4 becomes �ti = (CT)2 �ci. If an agent keeps\nasking the opinions of its friends of friends, the whole trust graph can be explored, and\nEq. 2.4 becomes Eq. 2.5, where n is the number of hops from i.\n\n�t = (CT )n �ci (2.5)\n\nThe trust scores of the agents converge to a global value irrespective of the trustee.\nBecause EigenTrust outputs global trust scores (normalized over the sum of all agents),\n\nagents are ranked according to their trust scores (unlike PeerTrust). Therefore, an agent\nis considered trustworthy if it is within a certain rank.\n\nAppleseed\n\nAppleseed is a flow-based algorithm [3]. Assuming that we are given a directed weighted\ngraph with agents as nodes, edges as trust relationships, and the weight of an edge as\ntrustworthiness of the sink, we can determine the amount of trust that flows in the graph.\nThat is, given a trust seed, an energy in ∈ R+0 , spreading factor decay ∈[ 0, 1], and conver-\ngence threshold Tc, Appleseed returns a trust score of agents from the perspective of the\ntrust seed.\nThe trust propagation from agent a to agent b is determined using Eq. 2.6, where the\n\nweight of edge (a, b) represents the amount of trust a places in b, and in(a) and in(b)\nrepresent the flow of trust into a and b, respectively.\n\nin(b) = decay ×\n∑\n\n(a,b)∈E\nin(a) × weight(a, b)∑\n\n(a,c)∈E weight(a, c)\n(2.6)\n\nThe trust of an agent b (trust(b)) is then updated using Eq. 2.7, where the decay factor\nensures that trust in an agent decreases as the path length from the seed increases.\n\ntrust(b) := trust(b) + (1 − decay) × in(b) (2.7)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 6 of 27\n\nGenerally, trust graphs have loops, which makes Eq. 2.7 recursive. Thus a termination\ncondition like the one below is required, where Ai ⊆ A is the set of nodes that were\ndiscovered until step i and trusti(x) is the current trust scores for all x ∈ Ai:\n\n∀x ∈ Ai : trusti(x) − trusti−1(x) ≤ Tc (2.8)\n\nAfter Eq. 2.7 terminates, the trust scores of agents are ranked. Since this set is ranked\nfrom the perspective of the seed, Appleseed is a local trust algorithm.\nAs our brief survey shows, the trust models vary in terms of their input, output, and\n\nthe methods they use. To evaluate and compare them, testbeds are needed. In the next\nsection we take a look at existing testbeds.\n\nTestbeds\n\nWe investigated two testbed models, namely Guha’s [15] and Macau [16], and two testbed\nimplementations, namely ART [17] and TREET [18], which are used to evaluate trust\nalgorithms. This section provides details of our investigation.\n\nGuha\n\nGuha [15] proposes a model to capture document recommendation systems, where trust\nand reputation play an important role. The model relies on a graph of agents where the\nedges can be weighted based on their mutual ratings, and a rating function for documents\nby agents. Guha then discusses how trust can be calculated based on those ratings, and\nevaluates a few case studies of real systems that can be accommodated by the model.\nGuha’s model can capture trust systems that take a set of documents and their ratings\n\nas input (such as Credence [10]), but it cannot accommodate systems where the only\ninput consists of direct feedbacks between agents, such as in PeerTrust (global) [2] or\nEigenTrust [1]. Also, the rating of documents is itself an output of Guha’s model, and that\nis often not the purpose or output of many more general-purpose trust models.\nIn short, document recommendation systems can be viewed as a specialization or\n\nsubclass of more general trust systems, and Guha’s model is suitable for that subclass.\n\nMacau\n\nHazard and Singh’s Macau [16] is a model for evaluating reputation systems. The authors\ndistinguish two roles for any agent: a rater that evaluates a target. Transactions are viewed\nas a favor provided by the target to the rater. The target’s reputation, local to each rater-\ntarget pairing, is updated after each transaction and depends on the previous reputation\nvalue. The target’s payoff in giving a favor is also dependent on its current reputation but\nalso on its belief of the likelihood that the rater will in turn return the favor in the future.\nBased on the above definitions, the authors define a set of desirable properties for a\n\nreputation system:\n\n• Monotonicity: given two different targets a and b, the computed reputation of a\nshould be higher than that of b if the predicted payoff of a transaction with a is\nhigher than with b.\n\n• Unambiguity and convergence: the reputation should converge over time to a single\nfixpoint, regardless of its initial value.\n\n• Accuracy: this convergence should happen quickly, thus minimizing the total\nreputation estimation errors in the meantime.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 7 of 27\n\nMacau thus captures an important stage in trust assessment, i.e. the update of one-to-\none trustworthiness based on past transactions. It has been used to evaluate, in terms of\ntheir compliance to the properties defined above, algorithms such as TRAVOS [6] and the\nBeta Reputation System (BRS) [7] that model positive and negative experiences as ran-\ndom variables following a beta probability distribution. The comparison of trust models\nrelying on the beta distribution and their resilience to various attacks has also recently\nbeen explored in [19].\n\nART\n\nThe Agent Reputation and Trust testbed (ART) [17] provides an open-source message-\ndriven simulation engine for implementing and comparing the performance of reputation\nsystems. ART uses art painting sales as the domain.\nEach client has to sell paintings belonging to a particular era. To determine their\n\nmarket values, clients refer to agents for appraisals for a fee. Because each agent\nis an expert only in a specific era, it may not be able to provide appraisals for\npaintings from other eras and therefore refers to other agents for a fee. After such\ninteractions, agents record their experiences, calculate their reputation scores, and\nuse them to choose the most trustworthy agents for future interactions. The goal\nof each agent is to finish the simulation with the highest bank balance, and, intu-\nitively, the winning agent’s trust mechanism knows the right agents to trust for\nrecommendations.\nThe ART testbed provides a protocol that each agent must implement. The protocol\n\nspecifies the possible messages that agents can send to each other. The messages are deliv-\nered by the simulation engine, which loops over each agent at every time interval. The\nengine is also responsible for keeping track of the bank balance of the agents, and assign-\ning new clients to agents. All results are collected and stored in a database and displayed\non a graphical user interface (GUI) at runtime.\nART is best suited for evaluating trust calculation schemes from a first person point\n\nof view. It is not meant as a platform for testing trust management as a service provided\nby the system. For example, to evaluate EigenTrust in ART, one would either need to\nconsiderably modify ART itself (for the centralized version of EigenTrust) or to require\ncooperation from the participating agents and an additional dedicated distributed infras-\ntructure (for the distributed version). Furthermore, as also pointed out in [16] and [20],\nthe comparison of the performance of different agents is not necessarily based on their\ncorrect ability to assess the reputation of other agents, but rather based on how well they\nmodel and exploit the problem domain.\n\nTREET\n\nThe Trust and Reputation Experimentation and Evaluation Testbed (TREET) [18] mod-\nels a general marketplace scenario where there are buyers, sellers, and 1,000 different\nproducts with varying prices, such that there are more inexpensive items than expensive\nones. The sale price of the products is fixed, to avoid the influence of market competition.\nThe cost of producing an item is 75 % of the selling price, and the seller incurs this cost.\nTo lower this cost and increase profit, a seller can cheat by not shipping the item. Each\nproduct also has a utility value of 110 % of the selling price, which encourages buyers to\npurchase.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 8 of 27\n\nAgents join or exit after 100 simulation days or after a day with a probability of 0.05,\nbut to keep the number of buyers and sellers constant, an agent is introduced for each\ndeparting agent. At initialization, each seller is assigned a random number of products\nto sell. Buyers evaluate the offers from each seller and pick a seller. Sellers are informed\nof the accepted offers and are paid. Fourteen days after a sale, the buyer knows whether\nhe has been cheated or not, depending on whether he receives the purchased item. The\nbuyer then provides feedback based on his experience of the transaction. The feedback is\nin turn used to choose sellers for future transactions.\nTREET evaluates the performance of various reputation systems under Reputation Lag\n\nattack, Proliferation attack, and Value Imbalance attack using the following metrics:\n\n1. cheater sales over honest sales ratio\n2. cheater profit over honest profit ratio\n\nMultiple seller accounts are needed to orchestrate a Proliferation Attack, but TREET\ndoes not consider attacks such as White-Washing and Self-Promoting, which require\ncreating multiple buyer accounts.\nTREET addresses many of ART’s limitation in a marketplace scenario. To name a\n\nfew [21], TREET supports both centralized and decentralized trust algorithms, allows\ncollusion attacks to be implemented, and does not put a restriction on trust score rep-\nresentation. However, like ART, the evaluation metrics in TREET are tightly coupled to\nthe marketplace domain. It is unclear how ART or TREET can be used to evaluate trust\nmodels used in other systems, such as P2P file-sharing networks, online product review\nwebsites and others that use trust. To our knowledge, there is no testbed that provides\ngeneric evaluation metrics and that is independent of the application domain.\n\nSummary\n\nTrust is a tool used in the decision-making process and it can be computed. There are\nmany models based on social trust that attempt to aid agents in making rational decisions.\nHowever, these models vary in terms of their input and output requirements. This makes\nevaluations against a common set of attacks difficult.\n\nProblem description and model\nOur goal is to have a testbed that is generic enough to accommodate as many trust\nmanagement systems and models as possible. Our requirements are:\n\n1. A model that provides an abstraction layer for developers to incorporate existing\nand new systems that match the input and output of the model.\n\n2. An evaluation framework to measure and compare the performance of trust models\nagainst trust properties and attacks independently of the application domain.\n\nIn this section, we introduce an abstract model for trust management systems. This\nmodel will be the foundation of our testbed. Our model is essentially based on the\nfollowing stages:\n\n1. In stage 1 of the trust assessment process, the feedback provided by agents on other\nagents is represented as a feedback history graph.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 9 of 27\n\n2. In stage 2, a reputation graph is produced, where the weight of an arc denotes the\nreputation of the target agent. “Reputation” here follows [14], as “an expectation\nabout an individual’s behavior based on information about or observations of its\npast behavior”. It is viewed as an estimation of trustworthiness based on a\ncombination of direct and indirect feedback.\n\n3. In the final stage, a trust graph is produced, where the existence of an arc implies\ntrust in the target agent. We take “trust” here to mean the “belief by agent A that\nagent B is trustworthy” [2, 22], and so it is boolean and subjective in our model.\n\nIn the rest of this section, we define the aforementioned graphs in stages.\n\nStage 1—obtain feedback history graph\n\nWe first define a feedback, f (a, b) ∈ R as an assessment made by agent a of an action or\ngroup of actions performed by agent b, where a and b belong to the set A of all the agents\nin the system. The list of n feedbacks by a on b, FHG(a, b), is called a feedback history,\nrepresented as follows:\n\nFHG(a, b) �→ (f1(a, b), f2(a, b), . . . , fn(a, b)) (3.1)\nThe feedback fi(a, b) indicates the ith satisfaction received by a from b’s action. For\n\nexample, in a file-sharing network, the feedback by a downloader may indicate the sat-\nisfaction received from downloading a file from an uploader in terms of a value in R.\nExisting trust models use different ranges of values for feedback, and letting the feedback\nvalue be in R allows us to include these reputation systems in our testbed.\nIf A is the set of agents, E is the set of labelled arcs (a, b), and the label is FHG(a, b)\n\nwhen FHG(a, b) \t= ∅, then the feedback histories for all agents in A are represented in a\ndirected and labelled graph called Feedback History Graph (FHG)2, FHG = (A, E):\n\nFHG : A × A → RN∗ (3.2)\nNote that we have not included timestamps associated with each feedback (which would\n\nbe useful for, among other things, running our testbed as a discrete event simulator), but\nour model can be expanded to accommodate it.\nOnce the feedback history graph is obtained, the next step is to produce a reputation\n\ngraph.\n\nStage 2—obtain reputation graph\n\nA Reputation Graph (RG), RG = (A, E′ ), is a directed and weighted graph, where the\nweight on an arc, RG(a, b), is the trustworthiness of b from a’s perspective:\n\nRG : A × A → R (3.3)\nThe edges are added by computing second and nth-hand trust via transitive closure of\n\nedges in E. That is: if (a, b) ∈ E and (b, c) ∈ E ⇒ (a, b), (b, c), and (a, c) ∈ E′ (the value of\nthe weight of the edges, however, depends on the particular trust algorithm).\nReputation algorithms may also exhibit the reflexive property by adding looping arcs to\n\nindicate that the truster trusts itself to a certain degree for a particular task [1–3].\nThe existing literature categorizes reputation algorithms into two groups: local and\n\nglobal (Figs. 1(a) and (b), respectively) [3, 5]. Global algorithms assign a single reputa-\ntion score to each agent. Therefore, if a global algorithm is used, then the weights of the\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 10 of 27\n\nFig. 1 Examples of reputation graphs output respectively by a local and global algorithm\n\nincoming arcs of an agent should be the same, as shown in Fig. 1(b) (although for clar-\nity’s sake we will often present the graph simply as a ranking of agents in the rest of this\narticle). There is no such property for local algorithms.\nReputation algorithms may also differ in how the graphs is produced. One method is\n\nto first calculate one-to-one scores of agents using direct feedbacks and then use them\nto calculate the trustworthiness of agents previously unknown to the truster (e.g., Eigen-\nTrust). This is shown as 1a and 1b in Fig. 2. The other method (#2 in Fig. 2) skips the\nintermediate graph in the aforementioned method and produces a reputation graph (e.g.,\nPeerTrust).\n\nStage 3—obtain trust graph\n\nThe graph obtained in stage 2 contains information about the trustworthiness of agents.\nBut to use this information to make a decision about a transaction in the future, agents\nmust convert trustworthiness to boolean trust (see [23] for an example), which can also\nbe expressed as a graph. We refer to this directed graph as the Trust Graph (TG) TG =\n(A, F), where a directed edge ab ∈ F represents agent a trusting agent b.\nTo summarize our model, we can represent the stages as part of a workflow as illustrated\n\nin Fig. 3.\n\nFig. 2 Two methods to obtain a reputation graph\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 11 of 27\n\nFig. 3 Overview of the stages in our model\n\nIn the next section, we see at what stages in our model do various algorithms fit, and\ndescribe criteria for chaining different algorithms.\n\nClassifying and chaining algorithms\nBy refactoring the trust models according to the stages presented in the above sections,\nwe start to see a new classification scheme. Let us take EigenTrust, PeerTrust, and Apple-\nseed as examples and describe them using our model. EigenTrust takes an FHG with\nedge labels in {0, 1}∗ as input and outputs an RG with edge labels in [ 0, 1]. PeerTrust,\non the other hand, takes an FHG with edge labels in [ 0, 1]∗ as input and outputs an\nRG with edge labels in [ 0, 1]. Meanwhile, Appleseed requires an RG with edge labels in\n[ 0, 1] as input and outputs another RG′ in the same codomain. It is also possible for an\nalgorithm to skip some stages. For example, according to our model, Aberer [5] skips\nstage 2 and does not output a reputation graph. One can also represent simple mecha-\nnisms to generate a trust graph by applying a threshold on reputation values (as output\nfor example by EigenTrust), or by selecting the top k agents. This stage transitions of\nalgorithms are depicted3 in Fig. 4. In addition to the existing classification criteria in the\nstate of the art, trust algorithms can now be classified according to their stage transi-\ntions (i.e., from one stage to another as well as transitioning within a stage) as shown in\nTable 1.\nIt is important to note that although these three algorithms output a reputation\n\ngraph with continuous reputation values between 0 and 1, the semantics of these val-\nues are different. EigenTrust outputs relative (among agents) global reputation scores,\nPeerTrust outputs an absolute global reputation score, and Appleseed produces relative\nlocal reputation scores. In other words, EigenTrust and Appleseed are ranking algorithms\n(global and local, respectively), whereas PeerTrust is not.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 12 of 27\n\nFig. 4 Stage transitions of Trust algorithms\n\nAs we can see, each step of the trust assessment process can be viewed as a\ngraph transformation function, and we can use this functional view to easily describe\nevaluation mechanisms as well. Suppose an experimenter wants to compare PeerTrust\nand EigenTrust. The inputs and outputs of these algorithms are semantically different.\nTo match the input, we can use a function that discretizes continuous feedback values\n(f (a, b)) in [0, 1] to {-1, 1}, using some threshold t:\n\nTable 1 A classification for trust models\n\nStage Global or\nAbsolute or\n\nTrust Algorithm\nTransitions\n\nInput\nLocal\n\nRelative\nReputation Scores\n\nEigenTrust 0 → 2 satisfaction global relative\nratings\n\nPeerTrust 0 → 2 satisfaction global absolute\nratings\n\nAppleSeed 2 → 2 reputation local absolute\nscores\n\nAberer & Despotovic 0 → 3 complaints global N/A\nAdvogato 3 → 3 certificates local N/A\n\nTRAVOS 0 → 2 satisfaction local absolute\nratings\n\nRanking 2 → 3 reputation N/A relative\nsc",
        "metadata_storage_path": "aHR0cHM6Ly9ocmNvdXJzZXNzdG9yYWdlLmJsb2IuY29yZS53aW5kb3dzLm5ldC9wYXBlcnMvczQwNDkzLTAxNS0wMDE5LXoucGRm0",
        "people": [
          "Chandrasekaran",
          "Esfandiari",
          "Partheeban Chandrasekaran",
          "Babak Esfandiari",
          "Aberer",
          "Despotovic",
          "Abdul-Rahman",
          "Marsh",
          "Tij",
          "Guha",
          "Hazard",
          "Singh"
        ],
        "organizations": [
          "Department",
          "Carleton",
          "PeerTrust",
          "Appleseed",
          "EigenTrust",
          "eBay",
          "Advogato",
          "Creative Commons",
          "TRAVOS",
          "Beta Reputation System",
          "TidalTrust",
          "Aberer",
          "TRAVOS, BRS",
          "Credence",
          "Marsh",
          "AppleSeed",
          "cij",
          "gence threshold Tc",
          "TREET",
          "Apple",
          "& Despotovic"
        ],
        "keyphrases": [
          "new classi- fication scheme",
          "peer file-sharing applications",
          "social networking websites",
          "comprehensive test tool",
          "Attribution 4.0 International License",
          "original author(s",
          "three trust algorithms",
          "various trust properties",
          "computational trust mechanisms",
          "online community-based systems",
          "Creative Commons license",
          "computational trust models",
          "social trust models",
          "three reputation systems",
          "different trust models",
          "RESEARCH Open Access",
          "trust assessment workflow",
          "existing reputation systems",
          "existing models",
          "Many models",
          "different stages",
          "Trust Management",
          "trust relationship",
          "Multi-agent systems",
          "Computer Engineering",
          "Introduction Motivation",
          "simple averaging",
          "based scores",
          "Advogato website",
          "application-dependent metrics",
          "transformation stage",
          "unrestricted use",
          "appropriate credit",
          "first contribution",
          "second contribution",
          "evaluation schemes",
          "Trust testbed",
          "Esfandiari Journal",
          "latest model",
          "single model",
          "generic testbed",
          "increasing need",
          "past transactions",
          "graph transformations",
          "Carleton University",
          "larger number",
          "Partheeban Chandrasekaran",
          "slandering attacks",
          "two agents",
          "Babak Esfandiari",
          "DOI",
          "experiments",
          "analysis",
          "Correspondence",
          "Department",
          "1125 Colonel",
          "Drive",
          "Ottawa",
          "Ontario",
          "Canada",
          "Abstract",
          "tesbed",
          "flexibility",
          "design",
          "prototype",
          "EigenTrust",
          "PeerTrust",
          "Appleseed",
          "vulnerabilites",
          "compliance",
          "example",
          "discrepancies",
          "trade-offs",
          "resistance",
          "self-promotion",
          "Keywords",
          "growth",
          "users",
          "history",
          "interactions",
          "calculations",
          "ratings",
          "eBay",
          "researcher",
          "tools",
          "evaluations",
          "set",
          "vulnerabilities",
          "types",
          "Overview",
          "solution",
          "contributions",
          "paper",
          "family",
          "process",
          "succession",
          "vertices",
          "meaning",
          "edges",
          "article",
          "terms",
          "creativecommons",
          "licenses",
          "distribution",
          "reproduction",
          "medium",
          "source",
          "link",
          "changes",
          "crossmark",
          "org",
          "mailto",
          "Page",
          "presence",
          "existence",
          "variety",
          "certificate authority-based PKI trust models",
          "Trust management systems aid agents",
          "reputation-based trust management systems",
          "three different trust algorithms",
          "public key infras",
          "Social trust models",
          "basic trust properties",
          "social trust algorithms",
          "existing trust algorithms",
          "Beta Reputation System",
          "three systems",
          "reputation systems",
          "chaining algorithms",
          "mutual trust",
          "trust assertions",
          "trust score",
          "existing testbeds",
          "subtle interplay",
          "higher sensitivity",
          "lower sensitivity",
          "literature review",
          "implementation details",
          "actual mechanisms",
          "earlier direct",
          "indirect interactions",
          "e-commerce website",
          "third party",
          "Various inputs",
          "file-sharing network",
          "blogging website",
          "particular level",
          "specific context",
          "simple attacks",
          "self-promoting attacks",
          "Problem description",
          "research problem",
          "particular agent",
          "one attack",
          "friend chain",
          "past experiences",
          "testbed prototype",
          "aggregated trustworthiness",
          "evaluation results",
          "range",
          "differences",
          "way",
          "slandering",
          "Organization",
          "section",
          "Background",
          "state",
          "discussion",
          "Conclusions",
          "limitations",
          "tructures",
          "certificates",
          "The",
          "means",
          "order",
          "instance",
          "sellers",
          "trustworthy",
          "product",
          "drawbacks",
          "Chandrasekaran",
          "root",
          "recommendations",
          "turn",
          "recommenders",
          "Nature",
          "TRAVOS",
          "BRS",
          "satisfaction",
          "transaction",
          "P2P",
          "Aberer",
          "Despotovic",
          "plaints",
          "Advogato",
          "goal",
          "spam",
          "community",
          "TidalTrust",
          "beta probability density function",
          "late indirect trust scores",
          "other agents’ past experiences",
          "Spreading Activation model",
          "local trust scores",
          "global trust algorithms",
          "global trust score",
          "local trust algorithms",
          "three algorithms",
          "general trust",
          "Eigen- Trust",
          "Trust decisions",
          "similarity score",
          "file authenticity",
          "recommenda- tions",
          "different inputs",
          "thresholding techniques",
          "edge weights",
          "maximum “flow",
          "direct experience",
          "party recommendations",
          "different families",
          "next sections",
          "detailed descriptions",
          "respective sections",
          "satisfaction ratings",
          "trust graph",
          "direct interactions",
          "truster agent",
          "Credence",
          "votes",
          "files",
          "trustee",
          "gossiping",
          "information",
          "perspective",
          "survey",
          "Marsh",
          "Abdul-Rahman",
          "case",
          "percentage",
          "top",
          "value",
          "energy",
          "tor",
          "short",
          "third",
          "one",
          "scope",
          "testbed",
          "details",
          "output",
          "readers",
          "high local trust values",
          "low local trust values",
          "local direct trust score",
          "normalized local trust score",
          "global trust score computations",
          "current trust scores",
          "trans- action ratings",
          "local trust vector",
          "global trust scores",
          "fellow malicious agents",
          "gence threshold Tc",
          "global value",
          "trust relationships",
          "trust propagation",
          "trust graphs",
          "flow-based algorithm",
          "path length",
          "trust seed",
          "weighted graph",
          "Tij trij",
          "cij elements",
          "factor decay",
          "decay factor",
          "honest agents",
          "agent u",
          "agent j",
          "satisfaction rating",
          "transaction rating",
          "raters",
          "Eq.",
          "transactions",
          "system",
          "method",
          "input",
          "sij",
          "sum",
          "truster",
          "friends",
          "cijcjk",
          "matrix",
          "tik",
          "opinion",
          "number",
          "hops",
          "i.",
          "rank",
          "nodes",
          "trustworthiness",
          "sink",
          "amount",
          "R+0",
          "places",
          "loops",
          "termination",
          "condition",
          "Ai",
          "step",
          "∑",
          "open-source message- driven simulation engine",
          "two different targets",
          "two testbed implementations",
          "document recommendation systems",
          "beta probability distribution",
          "local trust algorithm",
          "reputation estimation errors",
          "two testbed models",
          "general-purpose trust models",
          "previous reputation value",
          "art painting sales",
          "general trust systems",
          "The Agent Reputation",
          "beta distribution",
          "two roles",
          "initial value",
          "real systems",
          "trust assessment",
          "brief survey",
          "important role",
          "case studies",
          "direct feedbacks",
          "current reputation",
          "single fixpoint",
          "important stage",
          "one trustworthiness",
          "dom variables",
          "various attacks",
          "particular era",
          "market values",
          "specific era",
          "other eras",
          "reputation scores",
          "trust algorithms",
          "next section",
          "rating function",
          "desirable properties",
          "negative experiences",
          "mutual ratings",
          "target pairing",
          "other agents",
          "Guha Guha",
          "seed",
          "methods",
          "look",
          "Macau",
          "TREET",
          "investigation",
          "graph",
          "documents",
          "many",
          "specialization",
          "subclass",
          "Hazard",
          "Singh",
          "authors",
          "rater",
          "favor",
          "payoff",
          "belief",
          "likelihood",
          "future",
          "definitions",
          "Monotonicity",
          "computed",
          "b.",
          "Unambiguity",
          "convergence",
          "time",
          "Accuracy",
          "total",
          "update",
          "positive",
          "comparison",
          "resilience",
          "performance",
          "domain",
          "client",
          "paintings",
          "appraisals",
          "expert",
          "dedicated distributed infras- tructure",
          "online product review websites",
          "trust score rep- resentation",
          "graphical user interface",
          "first person point",
          "P2P file-sharing networks",
          "honest sales ratio",
          "trust calculation schemes",
          "decentralized trust algorithms",
          "highest bank balance",
          "Value Imbalance attack",
          "general marketplace scenario",
          "various reputation systems",
          "Reputation Lag attack",
          "honest profit ratio",
          "multiple buyer accounts",
          "Multiple seller accounts",
          "The ART testbed",
          "distributed version",
          "utility value",
          "Proliferation attack",
          "cheater sales",
          "other systems",
          "marketplace domain",
          "Reputation Experimentation",
          "trust mechanism",
          "trust management",
          "The Trust",
          "future interactions",
          "time interval",
          "The engine",
          "new clients",
          "correct ability",
          "problem domain",
          "Evaluation Testbed",
          "varying prices",
          "inexpensive items",
          "market competition",
          "selling price",
          "future transactions",
          "following metrics",
          "evaluation metrics",
          "simulation engine",
          "simulation days",
          "trustworthy agents",
          "right agents",
          "participating agents",
          "different agents",
          "possible messages",
          "centralized version",
          "sale price",
          "random number",
          "collusion attacks",
          "winning agent",
          "1,000 different products",
          "departing agent",
          "protocol",
          "track",
          "results",
          "database",
          "GUI",
          "runtime",
          "platform",
          "service",
          "cooperation",
          "additional",
          "model",
          "buyers",
          "influence",
          "cost",
          "purchase",
          "probability",
          "initialization",
          "offers",
          "feedback",
          "experience",
          "White-Washing",
          "Self-Promoting",
          "limitation",
          "restriction",
          "others",
          "knowledge",
          "100",
          "obtain feedback history graph",
          "many trust management systems",
          "discrete event simulator",
          "generic evaluation metrics",
          "particular trust algorithm",
          "A Reputation Graph",
          "trust assessment process",
          "Existing trust models",
          "many models",
          "new systems",
          "decision-making process",
          "evaluation framework",
          "labelled graph",
          "agent A",
          "Summary Trust",
          "social trust",
          "trust properties",
          "nth-hand trust",
          "application domain",
          "rational decisions",
          "abstraction layer",
          "n feedbacks",
          "ith satisfaction",
          "different ranges",
          "labelled arcs",
          "other things",
          "next step",
          "transitive closure",
          "target agent",
          "agent B",
          "indirect feedback",
          "feedback histories",
          "following stages",
          "past behavior",
          "common set",
          "final stage",
          "abstract model",
          "feedback value",
          "output requirements",
          "tool",
          "attacks",
          "developers",
          "foundation",
          "expectation",
          "individual",
          "observations",
          "estimation",
          "combination",
          "rest",
          "graphs",
          "group",
          "actions",
          "list",
          "FHG",
          "downloader",
          "uploader",
          "R.",
          "values",
          "timestamps",
          "directed",
          "second",
          "E.",
          "∅",
          "single reputa- tion score",
          "absolute global reputation score",
          "new classification scheme",
          "continuous reputation values",
          "global reputation scores",
          "existing classification criteria",
          "stage transi- tions",
          "top k agents",
          "local reputation scores",
          "obtain trust graph",
          "Global algorithms",
          "existing literature",
          "one scores",
          "Reputation algorithms",
          "particular task",
          "two groups",
          "clar- ity",
          "Two methods",
          "trust models",
          "above sections",
          "Apple- seed",
          "other hand",
          "same codomain",
          "other words",
          "reputation graph",
          "various algorithms",
          "different algorithms",
          "edge labels",
          "local algorithms",
          "other method",
          "intermediate graph",
          "reflexive property",
          "incoming arcs",
          "among agents",
          "ranking algorithms",
          "One method",
          "trusting agent",
          "EigenTrust outputs",
          "one stage",
          "looping",
          "degree",
          "Figs",
          "weights",
          "Fig.",
          "Examples",
          "decision",
          "TG",
          "stages",
          "workflow",
          "Classifying",
          "RG",
          "nisms",
          "threshold",
          "transitions",
          "addition",
          "Table",
          "semantics",
          "relative",
          "2 satisfaction global absolute ratings",
          "2 satisfaction global relative ratings",
          "Trust Algorithm Transitions Input",
          "absolute ratings Ranking",
          "continuous feedback values",
          "trust models Stage",
          "graph transformation function",
          "Stage transitions",
          "absolute scores",
          "Trust algorithms",
          "functional view",
          "evaluation mechanisms",
          "Reputation Scores",
          "2 reputation",
          "3 reputation",
          "experimenter",
          "inputs",
          "outputs",
          "classification",
          "AppleSeed",
          "3 complaints",
          "3 certificates",
          "N/A"
        ],
        "masked_text": "\n************** and ********** Journal of Trust Management  (****) *** \nDOI 10.1186/s40493-015-0019-z\n\nRESEARCH Open Access\n\nToward a testbed for evaluating\ncomputational trust models: experiments\nand analysis\n************************* and *****************\n\n*Correspondence:\n*********************\n********************* and\nComputer Engineering, ********\nUniversity, **********************\nOttawa, Ontario K1s5B6, Canada\n\nAbstract\nWe propose a generic testbed for evaluating social trust models and we show how\nexisting models can fit our tesbed. To showcase the flexibility of our design, we\nimplemented a prototype and evaluated three trust algorithms, namely EigenTrust,\n********* and *********, for their vulnerabilites to attacks and compliance to various\ntrust properties. For example, we were able to exhibit discrepancies between\nEigenTrust and PeerTrust, as well as trade-offs between resistance to slandering attacks\nversus self-promotion.\n\nKeywords: Trust testbed; Reputation; Multi-agent systems\n\nIntroduction\nMotivation\n\nWith the growth of online community-based systems such as peer-to-peer file-sharing\napplications, e-commerce and social networking websites, there is an increasing need to\nprovide computational trust mechanisms to determine which users or agents are honest\nand which ones are malicious. Many models calculate trust by relying on analyzing a\nhistory of interactions. The calculations can range from the simple averaging of ratings\non **** to flow-based scores in the ******** website. Thus for a researcher to evaluate\nand compare his or her latest model against existing ones, a comprehensive test tool is\nneeded. However, our research shows that the tools that exist to assist researchers are not\nflexible enough to include different trust models and their evaluations. Moreover, these\ntools use their own set of application-dependent metrics to evaluate a reputation system.\nThis means that a number of trust models cannot be evaluated for vulnerabilities against\ncertain types of attacks. Thus, there is still a need for a generic testbed to evaluate and\ncompare computational trust models.\n\nOverview of our solution and contributions\n\nIn this paper, we present a model and a testbed for evaluating a family of trust algo-\nrithms that rely on past transactions between ******. Trust assessment is viewed as a\nprocess consisting of a succession of graph transformations, where the agents form the\nvertices of the graph. The meaning of the edges depends on the transformation stage,\n\n© **** ************** and **********. Open Access This article is distributed under the terms of the Creative Commons\nAttribution 4.0 International License (********************************************, which permits unrestricted use, distribution,\nand reproduction in any medium, provided you give appropriate credit to the original ******(s) and the source, provide a link to\nthe Creative Commons license, and indicate if changes were made.\n\n********************************************************************************\nmailto: *********************\n*******************************************\n\n\n************** and Esfandiari Journal of Trust Management  (****) *** Page 2 of 27\n\nand can refer to the presence of transactions between the two agents or the existence\nof a trust relationship between them. Our first contribution is to show that with this\nview, existing reputation systems can be adopted under a single model, but they work at\ndifferent stages of the trust assessment workflow. This allows us to present a new classi-\nfication scheme for a number of trust models based on where they fit in the assessment\nworkflow. The second contribution of our work is that this workflow can be described\nformally, and by doing this, we show that it is possible to model a variety of attacks\nand evaluation schemes. Finally, out of the larger number of systems we classified, we\nselected three reputation systems, namely ********** [1], ********* [2] and *********\n[3], to exemplify the range and variety of reputation systems that our testbed can accom-\nmodate. We evaluated these three systems in our testbed against simple attacks and\nwe validated their compliance to basic trust properties. In particular, we were able to\nexhibit differences in the way ********** and ********* rank the agents, we observed\nthe subtle interplay between slandering and self-promoting attacks (higher sensitivity\nto one attack can lead to lower sensitivity to the other), and we verified that trust\nweakens along a friend-of-a-friend chain and that it is more easily lost than gained\n(as it should be).\n\nOrganization\n\nThis article is organized as follows: section ‘Background and literature review’ provides\nbackground and state of the art on trust models, attacks against them, and existing\ntestbeds for evaluation. Section ‘Problem description and model’ formulates the research\nproblem of this article and proposes our model for a testbed. Section ‘Classifying and\nchaining algorithms’ shows how some of existing trust algorithms can fit our model, and\nhow one can combine or compare them using our model and testbed. Section ‘Results and\ndiscussion’ describes the implementation details of our testbed prototype and presents\nevaluation results of three different trust algorithms, namely EigenTrust, PeerTrust, and\n*********. Section ‘Conclusions’ concludes this article and summarizes the contributions\nand limitations of our work.\n\nBackground and literature review\nSocial trust models\n\nTrust management systems aid ****** in establishing and assessing mutual trust. How-\never, the actual mechanisms used in these systems vary. For example, public key infras-\ntructures [4] rely on certificates whereas reputation-based trust management systems are\nbased on experiences of earlier direct and indirect interactions [5].\nIn this paper we will focus on social trust models based on reputation. The trust model\n\nshould provide a means to compare the trustworthiness of agents in order to choose a\nparticular ***** to perform an action. For instance, on an e-commerce website like ****,\nwe need to be able to compare the trustworthiness of sellers in order to pick the most\ntrustworthy one to buy a product from.\nSocial trust models rely on past experiences of ****** to produce trust assertions. That\n\nis, the agents in the system interact with each other and record their experiences, which\nare then used to determine whether a particular ***** is trustworthy. This model is self-\nsufficient because it does not rely on a third party to propagate trust, like it would in\ncertificate authority-based PKI trust models. However, there are drawbacks to having no\n\n\n\n************** and ********** Journal of Trust Management  (****) *** Page 3 of 27\n\nroot of trust. For instance, ****** evaluating the trustworthiness of ****** with whom\nthere has been no interaction must use recommendations from others and, in turn,\nevaluate the trustworthiness of the ************. Social trust models must address this\nproblem.\n\nNature of input\n\nVarious inputs are used by social trust algorithms to measure the trustworthiness of\n******. In EigenTrust [1], PeerTrust [2], TRAVOS [6] and Beta Reputation System (BRS)\n[7], ****** rate their satisfaction after a transaction (e.g., downloading a file in a P2P\nfile-sharing network). These ratings are used to obtain a trust score that represents the\ntrustworthiness of the *****. In ****** and **********’s system [5]1, ****** *** file com-\nplaints (can be seen as dissatisfaction) about each other after a transaction. In Advogato\n[8], whose goal is to discourage spam on its blogging website, ***** explicitly certify\neach other as belonging to a particular level in the community. Trust algorithms ***\nalso directly use trust scores among agents to compute an aggregated trustworthiness\nof ******, as in TidalTrust [9] and ********* [3]. In the specific context of P2P file-\nsharing, ******** [10] uses the votes on file authenticity to calculate a similarity score\nbetween ****** and uses it to measure trust. The trust score is then used to recommend\nfiles.\n\nDirect vs. indirect trust\n\nThe truster *** use some or all of its own and other agents’ past experiences with the\n******* to obtain a trust score. Trust algorithms often use gossiping to poll agents with\nwhom the ******* has had interactions in the past.\nThe trust score calculated using only the experiences from direct interactions is\n\ncalled the direct trust score, while the trust score calculated using the recommenda-\ntions from other agents is called the indirect trust score [11]. As mentioned earlier,\nreputation systems use different inputs (satisfaction ratings, votes, certificates, etc.) to\ncalculate direct trust scores and indirect trust scores. ********* uses satisfaction ratings\nto calculate both direct and indirect trust scores, whereas ********** and ******\nuse satisfaction ratings to calculate direct trust scores, which they then use to calcu-\nlate indirect trust scores. Therefore, we can categorize the trust algorithms based on\nthe input required. But how do trust algorithms calculate the trust scores of agents\nusing the above information? It again varies from algorithm to algorithm. For instance,\n*********, **********, and ****** use simple averaging of ratings, TRAVOS and BRS\nuse the beta probability density function, and ********* uses the Spreading Activation\nmodel.\n\nGlobal vs. local trust\n\nThe trust algorithm *** output a global trust score or a local trust score [3, 12]. A global\ntrust score is one that represents the general trust that all agents have on a particular\n*****, whereas local trust scores represents the trust from the perspective of the *******\nand thus each ******* *** trust an ***** differently. In our survey, we found *********,\n**********, and ****** to be global trust algorithms whereas ******, ***, ********,\n********, **********, *********, ***** [13] and ************ [14] are local trust\nalgorithms.\n\n\n\n************** and ********** Journal of Trust Management  (****) *** Page 4 of 27\n\nTo trust or not to trust\n\nOnce the trust score is calculated, it can be used to decide whether to trust the *****. It\ncan be as simple as comparing the trust score against a threshold: if the trust score is above\na certain threshold, then the ***** is trusted. ***** [13], and ****** [5] use thresholding\ntechniques. If the trust algorithm outputs normalized trust scores of agents as in Eigen-\nTrust, then the trust scores of ****** are ranked. In this case, ******* consider a certain\npercentage of the top ranked ****** as trustworthy. In *********, a graph is first obtained\nwith trust scores of agents as edge weights, and then, the ******* ***** is “injected” with\na value called the activation energy. This energy is spread to agents with a spreading fac-\ntor along the edges in the graph and the algorithm ranks the agents according to their\ntrust scores. Trust decisions can also be flow-based such as in ********, which calculates\na maximum “flow of trust” in the trust graph to determine which agents are trustworthy\nand which are not.\nIn short, social trust models focus on the following:\n\n1. What is the input to calculate the trust score of an *****?\n2. Does the trust algorithm use only direct experience or does it also rely on *****\n\nparty recommendations?\n3. Is the trust score of an ***** global or local?\n4. How does one decide whether to trust an *****?\n\nGiven the above discussion, and to assess the scope of our testbed, we propose to model,\nevaluate and compare three algorithms from fairly different families. The next sections\nprovide detailed descriptions of the trust models we selected and that we implemented in\nour testbed. The details are given to help understand the output of our experiments, but\nreaders familiar with **********, ********* and/or ********* *** skip those respective\nsections.\n\n*********\n\nIn *********, ****** rate each other in terms of the satisfaction received. These ratings\nare weighted by trust scores of the raters, and a global trust score is computed recursively\nusing Eq. 2.1, where:\n\n• T(u) is the trust score of agent u\n• I(u) is the set of transactions that agent u had with all the agents in the system\n• S(u, i) is the satisfaction rating on u for transaction i\n• p(u, i) is the ***** that provided the rating.\n\nT(u) =\nI(u)∑\ni=1\n\nS(u, i) × T(p(u, i))∑I(u)\nj=1 T(p(u, j))\n\n(2.1)\n\n********* also provides a method for calculating local trust scores. In both local and\nglobal trust score computations, the trust score is compared against a threshold to decide\nwhether to trust or not.\n\n**********\n\n****** in ********** rate transactions as satisfactory or unsatisfactory [1]. These trans-\naction ratings are used as input, to calculate a local direct trust score, from which a global\ntrust score is then calculated.\n\n\n\n************** and Esfandiari Journal of Trust Management  (****) *** Page 5 of 27\n\nAn agent i calculates the normalized local trust score of agent j, as shown in Eq. 2.2,\nwhere tij ∈ {+1, −1} is the transaction rating, and sij is the sum of ratings.\n\nsij =\n∑\n***\n\ntrij\n\ncij =\nmax(sij, 0)∑\nk max(sik, 0)\n\n(2.2)\n\nNote that we cannot use sij as the local trust score without normalizing, because mali-\ncious agents can arbitrarily assign high local trust values to fellow malicious agents and\nlow local trust values to honest ******.\nTo calculate the global trust score of an *****, the ******* queries his ******* for their\n\ntrust scores on the *******. These local trust scores are aggregated, as shown in Eq. 2.3.\n\ntik =\n∑\nj\ncijcjk (2.3)\n\nIf we let C be the matrix containing cij elements, �ci be the local trust vector for i (each\nelement corresponds to the trust that i has in j), and �ti the vector containing tik, then,\n\n�ti = CT �ci (2.4)\n\nBy asking a ******’s ******’s opinion, Eq. 2.4 becomes �ti = (CT)2 �ci. If an agent keeps\nasking the opinions of its ******* of *******, the whole trust graph can be explored, and\nEq. 2.4 becomes Eq. 2.5, where n is the number of hops from i.\n\n�t = (CT )n �ci (2.5)\n\nThe trust scores of the ****** converge to a global value irrespective of the *******.\nBecause ********** outputs global trust scores (normalized over the sum of all ******),\n\n****** are ranked according to their trust scores (unlike *********). Therefore, an agent\nis considered trustworthy if it is within a certain rank.\n\n*********\n\nAppleseed is a flow-based algorithm [3]. Assuming that we are given a directed weighted\ngraph with agents as nodes, edges as trust relationships, and the weight of an edge as\ntrustworthiness of the sink, we can determine the amount of trust that flows in the graph.\nThat is, given a trust seed, an energy in ∈ R+0 , spreading factor decay ∈[ 0, 1], and conver-\ngence threshold Tc, ********* returns a trust score of agents from the perspective of the\ntrust seed.\nThe trust propagation from agent a to agent b is determined using Eq. 2.6, where the\n\nweight of edge (a, b) represents the amount of trust a places in b, and in(a) and in(b)\nrepresent the flow of trust into a and b, respectively.\n\nin(b) = decay ×\n∑\n\n(a,b)∈E\nin(a) × weight(a, b)∑\n\n(a,c)∈E weight(a, c)\n(2.6)\n\nThe trust of an agent b (trust(b)) is then updated using Eq. 2.7, where the decay factor\nensures that trust in an ***** decreases as the path length from the seed increases.\n\ntrust(b) := trust(b) + (1 − decay) × in(b) (2.7)\n\n\n\n************** and Esfandiari Journal of Trust Management  (****) *** Page 6 of 27\n\nGenerally, trust graphs have loops, which makes Eq. 2.7 recursive. Thus a termination\ncondition like the one below is required, where Ai ⊆ A is the set of nodes that were\ndiscovered until step i and trusti(x) is the current trust scores for all x ∈ Ai:\n\n∀x ∈ Ai : trusti(x) − trusti−1(x) ≤ Tc (2.8)\n\nAfter Eq. 2.7 terminates, the trust scores of ****** are ranked. Since this set is ranked\nfrom the perspective of the seed, Appleseed is a local trust algorithm.\nAs our brief survey shows, the trust models vary in terms of their input, output, and\n\nthe methods they use. To evaluate and compare them, testbeds are needed. In the next\nsection we take a look at existing testbeds.\n\nTestbeds\n\nWe investigated two testbed models, namely Guha’s [15] and Macau [16], and two testbed\nimplementations, namely ART [17] and TREET [18], which are used to evaluate trust\nalgorithms. This section provides details of our investigation.\n\nGuha\n\n**** [15] proposes a model to capture document recommendation systems, where trust\nand reputation play an important role. The model relies on a graph of agents where the\nedges can be weighted based on their mutual ratings, and a rating function for documents\nby ******. **** then discusses how trust can be calculated based on those ratings, and\nevaluates a few case studies of real systems that can be accommodated by the model.\n****’s model can capture trust systems that take a set of documents and their ratings\n\nas input (such as Credence [10]), but it cannot accommodate systems where the only\ninput consists of direct feedbacks between agents, such as in PeerTrust (global) [2] or\n********** [1]. Also, the rating of documents is itself an output of ****’s model, and that\nis often not the purpose or output of many more general-purpose trust models.\nIn short, document recommendation systems can be viewed as a specialization or\n\nsubclass of more general trust systems, and ****’s model is suitable for that subclass.\n\nMacau\n\n****** and *****’s Macau [16] is a model for evaluating reputation systems. The authors\ndistinguish two roles for any *****: a ***** that evaluates a target. Transactions are viewed\nas a favor provided by the target to the *****. The target’s reputation, local to each rater-\ntarget pairing, is updated after each transaction and depends on the previous reputation\nvalue. The target’s payoff in giving a favor is also dependent on its current reputation but\nalso on its belief of the likelihood that the ***** will in turn return the favor in the future.\nBased on the above definitions, the ******* define a set of desirable properties for a\n\nreputation system:\n\n• Monotonicity: given two different targets a and b, the computed reputation of a\nshould be higher than that of b if the predicted payoff of a transaction with a is\nhigher than with b.\n\n• Unambiguity and convergence: the reputation should converge over time to a single\nfixpoint, regardless of its initial value.\n\n• Accuracy: this convergence should happen quickly, thus minimizing the total\nreputation estimation errors in the meantime.\n\n\n\n************** and Esfandiari Journal of Trust Management  (****) *** Page 7 of 27\n\nMacau thus captures an important stage in trust assessment, i.e. the update of one-to-\none trustworthiness based on past transactions. It has been used to evaluate, in terms of\ntheir compliance to the properties defined above, algorithms such as TRAVOS [6] and the\nBeta Reputation System (BRS) [7] that model positive and negative experiences as ran-\ndom variables following a beta probability distribution. The comparison of trust models\nrelying on the beta distribution and their resilience to various attacks has also ********\nbeen explored in [19].\n\nART\n\nThe Agent Reputation and Trust testbed (ART) [17] provides an open-source message-\ndriven simulation engine for implementing and comparing the performance of reputation\nsystems. *** uses art painting sales as the domain.\nEach ****** has to sell paintings belonging to a particular era. To determine their\n\nmarket values, ******* refer to ****** for appraisals for a fee. Because each agent\nis an expert only in a specific era, it may not be able to provide appraisals for\npaintings from other eras and therefore refers to other ****** for a fee. After such\ninteractions, ****** record their experiences, calculate their reputation scores, and\nuse them to choose the most trustworthy ****** for future interactions. The goal\nof each ***** is to finish the simulation with the highest bank balance, and, intu-\nitively, the winning agent’s trust mechanism knows the right agents to trust for\nrecommendations.\nThe ART testbed provides a protocol that each ***** must implement. The protocol\n\nspecifies the possible messages that ****** can send to each other. The messages are deliv-\nered by the simulation engine, which loops over each ***** at every time interval. The\nengine is also responsible for keeping track of the bank balance of the agents, and assign-\ning new ******* to ******. All results are collected and stored in a database and displayed\non a graphical user interface (GUI) at runtime.\nART is best suited for evaluating trust calculation schemes from a first person point\n\nof view. It is not meant as a platform for testing trust management as a service provided\nby the system. For example, to evaluate EigenTrust in ART, one would either need to\nconsiderably modify ART itself (for the centralized version of EigenTrust) or to require\ncooperation from the participating agents and an additional dedicated distributed infras-\ntructure (for the distributed version). Furthermore, as also pointed out in [16] and [20],\nthe comparison of the performance of different agents is not necessarily based on their\ncorrect ability to assess the reputation of other agents, but rather based on how well they\nmodel and exploit the problem domain.\n\nTREET\n\nThe Trust and Reputation Experimentation and Evaluation Testbed (TREET) [18] mod-\nels a general marketplace scenario where there are buyers, sellers, and 1,000 different\nproducts with varying prices, such that there are more inexpensive items than expensive\nones. The sale price of the products is fixed, to avoid the influence of market competition.\nThe cost of producing an item is 75 % of the selling price, and the ****** incurs this cost.\nTo lower this cost and increase profit, a ****** can cheat by not shipping the item. Each\nproduct also has a utility value of 110 % of the selling price, which encourages ****** to\npurchase.\n\n\n\n************** and Esfandiari Journal of Trust Management  (****) *** Page 8 of 27\n\n****** join or exit after 100 simulation days or *********** with a probability of 0.05,\nbut to keep the number of buyers and ******* constant, an ***** is introduced for each\ndeparting *****. At initialization, each ****** is assigned a random number of products\nto sell. ****** evaluate the offers from each ****** and pick a ******. Sellers are informed\nof the accepted offers and are paid. ************* after a sale, the ***** knows whether\nhe has been cheated or not, depending on whether he receives the purchased item. The\n***** then provides feedback based on his experience of the transaction. The feedback is\nin turn used to choose ******* for future transactions.\nTREET evaluates the performance of various reputation systems under Reputation Lag\n\nattack, Proliferation attack, and Value Imbalance attack using the following metrics:\n\n1. cheater sales over honest sales ratio\n2. cheater profit over honest profit ratio\n\nMultiple seller accounts are needed to orchestrate a Proliferation Attack, but TREET\ndoes not consider attacks such as White-Washing and Self-Promoting, which require\ncreating multiple ***** accounts.\nTREET addresses many of ART’s limitation in a marketplace scenario. To name a\n\nfew [21], TREET supports both centralized and decentralized trust algorithms, allows\ncollusion attacks to be implemented, and does not put a restriction on trust score rep-\nresentation. However, like ART, the evaluation metrics in TREET are tightly coupled to\nthe marketplace domain. It is unclear how ART or TREET can be used to evaluate trust\nmodels used in other systems, such as P2P file-sharing networks, online product review\nwebsites and others that use trust. To our knowledge, there is no testbed that provides\ngeneric evaluation metrics and that is independent of the application domain.\n\nSummary\n\nTrust is a tool used in the decision-making process and it can be computed. There are\nmany models based on social trust that attempt to aid ****** in making rational decisions.\nHowever, these models vary in terms of their input and output requirements. This makes\nevaluations against a common set of attacks difficult.\n\nProblem description and model\nOur goal is to have a testbed that is generic enough to accommodate as many trust\nmanagement systems and models as possible. Our requirements are:\n\n1. A model that provides an abstraction layer for ********** to incorporate existing\nand new systems that match the input and output of the model.\n\n2. An evaluation framework to measure and compare the performance of trust models\nagainst trust properties and attacks independently of the application domain.\n\nIn this section, we introduce an abstract model for trust management systems. This\nmodel will be the foundation of our testbed. Our model is essentially based on the\nfollowing stages:\n\n1. In stage 1 of the trust assessment process, the feedback provided by ****** on other\nagents is represented as a feedback history graph.\n\n\n\n************** and Esfandiari Journal of Trust Management  (****) *** Page 9 of 27\n\n2. In stage 2, a reputation graph is produced, where the weight of an arc denotes the\nreputation of the target *****. “Reputation” here follows [14], as “an expectation\nabout an individual’s behavior based on information about or observations of its\npast behavior”. It is viewed as an estimation of trustworthiness based on a\ncombination of direct and indirect feedback.\n\n3. In the final stage, a trust graph is produced, where the existence of an arc implies\ntrust in the target *****. We take “trust” here to mean the “belief by agent A that\nagent B is trustworthy” [2, 22], and so it is boolean and subjective in our model.\n\nIn the rest of this section, we define the aforementioned graphs in stages.\n\nStage 1—obtain feedback history graph\n\nWe first define a feedback, f (a, b) ∈ R as an assessment made by agent a of an action or\ngroup of actions performed by agent b, where a and b belong to the set A of all the agents\nin the system. The list of n feedbacks by a on b, FHG(a, b), is called a feedback history,\nrepresented as follows:\n\nFHG(a, b) �→ (f1(a, b), f2(a, b), . . . , fn(a, b)) (3.1)\nThe feedback fi(a, b) indicates the ith satisfaction received by a from b’s action. For\n\nexample, in a file-sharing network, the feedback by a downloader *** indicate the sat-\nisfaction received from downloading a file from an ******** in terms of a value in R.\nExisting trust models use different ranges of values for feedback, and letting the feedback\nvalue be in R allows us to include these reputation systems in our testbed.\nIf A is the set of agents, E is the set of labelled arcs (a, b), and the label is FHG(a, b)\n\nwhen FHG(a, b) \t= ∅, then the feedback histories for all agents in A are represented in a\ndirected and labelled graph called Feedback History Graph (FHG)2, FHG = (A, E):\n\nFHG : A × A → RN∗ (3.2)\nNote that we have not included timestamps associated with each feedback (which would\n\nbe useful for, among other things, running our testbed as a discrete event simulator), but\nour model can be expanded to accommodate it.\nOnce the feedback history graph is obtained, the next step is to produce a reputation\n\ngraph.\n\nStage 2—obtain reputation graph\n\nA Reputation Graph (RG), RG = (A, E′ ), is a directed and weighted graph, where the\nweight on an arc, RG(a, b), is the trustworthiness of b from a’s perspective:\n\nRG : A × A → R (3.3)\nThe edges are added by computing second and nth-hand trust via transitive closure of\n\nedges in E. That is: if (a, b) ∈ E and (b, c) ∈ E ⇒ (a, b), (b, c), and (a, c) ∈ E′ (the value of\nthe weight of the edges, however, depends on the particular trust algorithm).\nReputation algorithms *** also exhibit the reflexive property by adding looping arcs to\n\nindicate that the ******* trusts itself to a certain degree for a particular task [1–3].\nThe existing literature categorizes reputation algorithms into two groups: local and\n\nglobal (Figs. 1(a) and (b), respectively) [3, 5]. Global algorithms assign a single reputa-\ntion score to each *****. Therefore, if a global algorithm is used, then the weights of the\n\n\n\n************** and Esfandiari Journal of Trust Management  (****) *** Page 10 of 27\n\nFig. 1 Examples of reputation graphs output respectively by a local and global algorithm\n\nincoming arcs of an agent should be the same, as shown in Fig. 1(b) (although for clar-\nity’s sake we will often present the graph simply as a ranking of agents in the rest of this\narticle). There is no such property for local algorithms.\nReputation algorithms may also differ in how the graphs is produced. One method is\n\nto first calculate one-to-one scores of agents using direct feedbacks and then use them\nto calculate the trustworthiness of ****** ********** unknown to the ******* (e.g., Eigen-\nTrust). This is shown as 1a and 1b in Fig. 2. The other method (#2 in Fig. 2) skips the\nintermediate graph in the aforementioned method and produces a reputation graph (e.g.,\n*********).\n\nStage 3—obtain trust graph\n\nThe graph obtained in stage 2 contains information about the trustworthiness of ******.\nBut to use this information to make a decision about a transaction in the future, agents\nmust convert trustworthiness to boolean trust (see [23] for an example), which can also\nbe expressed as a graph. We refer to this directed graph as the Trust Graph (TG) TG =\n(A, F), where a directed edge ab ∈ F represents agent a trusting agent b.\nTo summarize our model, we can represent the stages as part of a workflow as illustrated\n\nin Fig. 3.\n\nFig. 2 Two methods to obtain a reputation graph\n\n\n\n************** and Esfandiari Journal of Trust Management  (****) *** Page 11 of 27\n\nFig. 3 Overview of the stages in our model\n\nIn the next section, we see at what stages in our model do various algorithms fit, and\ndescribe criteria for chaining different algorithms.\n\nClassifying and chaining algorithms\nBy refactoring the trust models according to the stages presented in the above sections,\nwe start to see a new classification scheme. Let us take **********, *********, and *****-\nseed as examples and describe them using our model. ********** takes an FHG with\nedge labels in {0, 1}∗ as input and outputs an RG with edge labels in [ 0, 1]. *********,\non the other hand, takes an FHG with edge labels in [ 0, 1]∗ as input and outputs an\nRG with edge labels in [ 0, 1]. Meanwhile, ********* requires an RG with edge labels in\n[ 0, 1] as input and outputs another RG′ in the same codomain. It is also possible for an\nalgorithm to skip some stages. For example, according to our model, ****** [5] skips\nstage 2 and does not output a reputation graph. One can also represent simple mecha-\nnisms to generate a trust graph by applying a threshold on reputation values (as output\nfor example by **********), or by selecting the top k ******. This stage transitions of\nalgorithms are depicted3 in Fig. 4. In addition to the existing classification criteria in the\nstate of the art, trust algorithms can *** be classified according to their stage transi-\ntions (i.e., from one stage to another as well as transitioning within a stage) as shown in\nTable 1.\nIt is important to note that although these three algorithms output a reputation\n\ngraph with continuous reputation values between 0 and 1, the semantics of these val-\nues are different. ********** outputs relative (among ******) global reputation scores,\n********* outputs an absolute global reputation score, and ********* produces relative\nlocal reputation scores. In other words, ********** and ********* are ranking algorithms\n(global and local, respectively), whereas ********* is not.\n\n\n\n************** and Esfandiari Journal of Trust Management  (****) *** Page 12 of 27\n\nFig. 4 Stage transitions of Trust algorithms\n\nAs we can see, each step of the trust assessment process can be viewed as a\ngraph transformation function, and we can use this functional view to easily describe\nevaluation mechanisms as well. Suppose an experimenter wants to compare PeerTrust\nand EigenTrust. The inputs and outputs of these algorithms are semantically different.\nTo match the input, we can use a function that discretizes continuous feedback values\n(f (a, b)) in [0, 1] to {-1, 1}, using some threshold t:\n\nTable 1 A classification for trust models\n\nStage Global or\nAbsolute or\n\nTrust Algorithm\nTransitions\n\nInput\nLocal\n\nRelative\nReputation Scores\n\nEigenTrust 0 → 2 satisfaction global relative\nratings\n\nPeerTrust 0 → 2 satisfaction global absolute\nratings\n\nAppleSeed 2 → 2 reputation local absolute\nscores\n\n******************* 0 → 3 complaints global N/A\n******** 3 → 3 certificates local N/A\n\nTRAVOS 0 → 2 satisfaction local absolute\nratings\n\nRanking 2 → 3 reputation N/A relative\nsc",
        "pii_entities": [
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 1,
            "length": 14,
            "score": 0.71
          },
          {
            "text": "Esfandiari",
            "type": "Person",
            "subtype": null,
            "offset": 20,
            "length": 10,
            "score": 0.5
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 61,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 67,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "Partheeban Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 210,
            "length": 25,
            "score": 0.96
          },
          {
            "text": "Babak Esfandiari",
            "type": "Person",
            "subtype": null,
            "offset": 240,
            "length": 16,
            "score": 0.94
          },
          {
            "text": "babak@sce.carleton.ca",
            "type": "Email",
            "subtype": null,
            "offset": 276,
            "length": 21,
            "score": 0.8
          },
          {
            "text": "Department of Systems",
            "type": "Organization",
            "subtype": null,
            "offset": 298,
            "length": 21,
            "score": 0.69
          },
          {
            "text": "Carleton",
            "type": "Organization",
            "subtype": null,
            "offset": 346,
            "length": 8,
            "score": 0.67
          },
          {
            "text": "1125 Colonel By Drive,",
            "type": "Address",
            "subtype": null,
            "offset": 367,
            "length": 22,
            "score": 0.93
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 674,
            "length": 9,
            "score": 0.76
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 688,
            "length": 9,
            "score": 0.86
          },
          {
            "text": "eBay",
            "type": "Organization",
            "subtype": null,
            "offset": 1467,
            "length": 4,
            "score": 0.89
          },
          {
            "text": "Advogato",
            "type": "Organization",
            "subtype": null,
            "offset": 1500,
            "length": 8,
            "score": 0.69
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 2306,
            "length": 6,
            "score": 0.96
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 2521,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 2526,
            "length": 14,
            "score": 0.56
          },
          {
            "text": "Esfandiari",
            "type": "Person",
            "subtype": null,
            "offset": 2545,
            "length": 10,
            "score": 0.51
          },
          {
            "text": "http://creativecommons.org/licenses/by/4.0/)",
            "type": "URL",
            "subtype": null,
            "offset": 2676,
            "length": 44,
            "score": 0.8
          },
          {
            "text": "author",
            "type": "PersonType",
            "subtype": null,
            "offset": 2853,
            "length": 6,
            "score": 0.84
          },
          {
            "text": "http://crossmark.crossref.org/dialog/?doi=10.1186/s40493-015-0019-z-x&domain=pdf",
            "type": "URL",
            "subtype": null,
            "offset": 2963,
            "length": 80,
            "score": 0.8
          },
          {
            "text": "babak@sce.carleton.ca",
            "type": "Email",
            "subtype": null,
            "offset": 3052,
            "length": 21,
            "score": 0.8
          },
          {
            "text": "http://creativecommons.org/licenses/by/4.0/",
            "type": "URL",
            "subtype": null,
            "offset": 3074,
            "length": 43,
            "score": 0.8
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 3120,
            "length": 14,
            "score": 0.68
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 3180,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 3186,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 3944,
            "length": 10,
            "score": 0.72
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 3960,
            "length": 9,
            "score": 0.7
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 3978,
            "length": 9,
            "score": 0.74
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 4280,
            "length": 10,
            "score": 0.62
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 4295,
            "length": 9,
            "score": 0.59
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 5327,
            "length": 9,
            "score": 0.6
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 5529,
            "length": 6,
            "score": 0.9
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 6017,
            "length": 5,
            "score": 0.88
          },
          {
            "text": "eBay",
            "type": "Organization",
            "subtype": null,
            "offset": 6089,
            "length": 4,
            "score": 0.93
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 6269,
            "length": 6,
            "score": 0.91
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 6449,
            "length": 5,
            "score": 0.9
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 6672,
            "length": 14,
            "score": 0.75
          },
          {
            "text": "Esfandiari",
            "type": "Person",
            "subtype": null,
            "offset": 6691,
            "length": 10,
            "score": 0.52
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 6732,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 6738,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 6785,
            "length": 6,
            "score": 0.58
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 6826,
            "length": 6,
            "score": 0.73
          },
          {
            "text": "recommenders",
            "type": "PersonType",
            "subtype": null,
            "offset": 6960,
            "length": 12,
            "score": 0.96
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 7124,
            "length": 6,
            "score": 0.67
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 7215,
            "length": 6,
            "score": 0.92
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 7414,
            "length": 5,
            "score": 0.95
          },
          {
            "text": "Aberer",
            "type": "Person",
            "subtype": null,
            "offset": 7424,
            "length": 6,
            "score": 0.94
          },
          {
            "text": "Despotovic",
            "type": "Person",
            "subtype": null,
            "offset": 7435,
            "length": 10,
            "score": 0.96
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 7461,
            "length": 6,
            "score": 0.77
          },
          {
            "text": "may",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 7468,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "users",
            "type": "PersonType",
            "subtype": null,
            "offset": 7636,
            "length": 5,
            "score": 0.66
          },
          {
            "text": "may",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 7742,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 7834,
            "length": 6,
            "score": 0.61
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 7867,
            "length": 9,
            "score": 0.59
          },
          {
            "text": "Credence",
            "type": "Person",
            "subtype": null,
            "offset": 7928,
            "length": 8,
            "score": 0.91
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 8018,
            "length": 6,
            "score": 0.89
          },
          {
            "text": "may",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 8144,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "trustee",
            "type": "PersonType",
            "subtype": null,
            "offset": 8219,
            "length": 7,
            "score": 0.95
          },
          {
            "text": "truster",
            "type": "PersonType",
            "subtype": null,
            "offset": 8318,
            "length": 7,
            "score": 0.93
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 8766,
            "length": 9,
            "score": 0.68
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 8862,
            "length": 10,
            "score": 0.82
          },
          {
            "text": "TRAVOS",
            "type": "Organization",
            "subtype": null,
            "offset": 8877,
            "length": 6,
            "score": 0.72
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 9233,
            "length": 9,
            "score": 0.79
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 9244,
            "length": 10,
            "score": 0.88
          },
          {
            "text": "Aberer",
            "type": "Organization",
            "subtype": null,
            "offset": 9260,
            "length": 6,
            "score": 0.9
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 9362,
            "length": 9,
            "score": 0.73
          },
          {
            "text": "may",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 9454,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 9617,
            "length": 5,
            "score": 0.53
          },
          {
            "text": "truster",
            "type": "PersonType",
            "subtype": null,
            "offset": 9700,
            "length": 7,
            "score": 0.58
          },
          {
            "text": "truster",
            "type": "PersonType",
            "subtype": null,
            "offset": 9722,
            "length": 7,
            "score": 0.91
          },
          {
            "text": "may",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 9730,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 9743,
            "length": 5,
            "score": 0.95
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 9786,
            "length": 9,
            "score": 0.71
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 9797,
            "length": 10,
            "score": 0.75
          },
          {
            "text": "Aberer",
            "type": "Organization",
            "subtype": null,
            "offset": 9813,
            "length": 6,
            "score": 0.85
          },
          {
            "text": "TRAVOS",
            "type": "Organization",
            "subtype": null,
            "offset": 9858,
            "length": 6,
            "score": 0.79
          },
          {
            "text": "BRS",
            "type": "Organization",
            "subtype": null,
            "offset": 9866,
            "length": 3,
            "score": 0.84
          },
          {
            "text": "Credence",
            "type": "Organization",
            "subtype": null,
            "offset": 9871,
            "length": 8,
            "score": 0.79
          },
          {
            "text": "Advogato",
            "type": "Organization",
            "subtype": null,
            "offset": 9881,
            "length": 8,
            "score": 0.76
          },
          {
            "text": "TidalTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 9891,
            "length": 10,
            "score": 0.96
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 9903,
            "length": 9,
            "score": 0.92
          },
          {
            "text": "Marsh",
            "type": "Organization",
            "subtype": null,
            "offset": 9914,
            "length": 5,
            "score": 0.85
          },
          {
            "text": "Abdul-Rahman",
            "type": "Organization",
            "subtype": null,
            "offset": 9929,
            "length": 12,
            "score": 0.57
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 9978,
            "length": 14,
            "score": 0.8
          },
          {
            "text": "Esfandiari",
            "type": "Person",
            "subtype": null,
            "offset": 9997,
            "length": 10,
            "score": 0.53
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 10038,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 10044,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 10170,
            "length": 5,
            "score": 0.96
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 10305,
            "length": 5,
            "score": 0.95
          },
          {
            "text": "Marsh",
            "type": "Person",
            "subtype": null,
            "offset": 10323,
            "length": 5,
            "score": 0.91
          },
          {
            "text": "Aberer",
            "type": "Person",
            "subtype": null,
            "offset": 10339,
            "length": 6,
            "score": 0.94
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 10489,
            "length": 6,
            "score": 0.94
          },
          {
            "text": "one may",
            "type": "DateTime",
            "subtype": "Date",
            "offset": 10522,
            "length": 7,
            "score": 0.8
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 10578,
            "length": 6,
            "score": 0.89
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 10604,
            "length": 9,
            "score": 0.5
          },
          {
            "text": "truster",
            "type": "PersonType",
            "subtype": null,
            "offset": 10700,
            "length": 7,
            "score": 0.62
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 10708,
            "length": 5,
            "score": 0.75
          },
          {
            "text": "Advogato",
            "type": "Organization",
            "subtype": null,
            "offset": 10976,
            "length": 8,
            "score": 0.5
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 11220,
            "length": 5,
            "score": 0.92
          },
          {
            "text": "third",
            "type": "DateTime",
            "subtype": "Date",
            "offset": 11306,
            "length": 5,
            "score": 0.8
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 11364,
            "length": 5,
            "score": 0.93
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 11430,
            "length": 5,
            "score": 0.96
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 11815,
            "length": 10,
            "score": 0.66
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 11827,
            "length": 9,
            "score": 0.63
          },
          {
            "text": "AppleSeed",
            "type": "Organization",
            "subtype": null,
            "offset": 11844,
            "length": 9,
            "score": 0.66
          },
          {
            "text": "may",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 11854,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 11891,
            "length": 9,
            "score": 0.64
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 11905,
            "length": 9,
            "score": 0.64
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 11916,
            "length": 6,
            "score": 0.91
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 12307,
            "length": 5,
            "score": 0.78
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 12407,
            "length": 9,
            "score": 0.68
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 12611,
            "length": 10,
            "score": 0.52
          },
          {
            "text": "Agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 12623,
            "length": 6,
            "score": 0.86
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 12633,
            "length": 10,
            "score": 0.79
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 12844,
            "length": 14,
            "score": 0.68
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 12904,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 12910,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "Tij",
            "type": "Person",
            "subtype": null,
            "offset": 13104,
            "length": 3,
            "score": 0.54
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 13368,
            "length": 6,
            "score": 0.94
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 13418,
            "length": 5,
            "score": 0.78
          },
          {
            "text": "truster",
            "type": "PersonType",
            "subtype": null,
            "offset": 13429,
            "length": 7,
            "score": 0.77
          },
          {
            "text": "friends",
            "type": "PersonType",
            "subtype": null,
            "offset": 13449,
            "length": 7,
            "score": 0.73
          },
          {
            "text": "trustee",
            "type": "PersonType",
            "subtype": null,
            "offset": 13488,
            "length": 7,
            "score": 0.95
          },
          {
            "text": "friend",
            "type": "PersonType",
            "subtype": null,
            "offset": 13802,
            "length": 6,
            "score": 0.94
          },
          {
            "text": "friend",
            "type": "PersonType",
            "subtype": null,
            "offset": 13811,
            "length": 6,
            "score": 0.95
          },
          {
            "text": "friends",
            "type": "PersonType",
            "subtype": null,
            "offset": 13907,
            "length": 7,
            "score": 0.56
          },
          {
            "text": "friends",
            "type": "PersonType",
            "subtype": null,
            "offset": 13918,
            "length": 7,
            "score": 0.51
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 14081,
            "length": 6,
            "score": 0.92
          },
          {
            "text": "trustee",
            "type": "PersonType",
            "subtype": null,
            "offset": 14135,
            "length": 7,
            "score": 0.95
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 14152,
            "length": 10,
            "score": 0.79
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 14223,
            "length": 6,
            "score": 0.74
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 14233,
            "length": 6,
            "score": 0.85
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 14291,
            "length": 9,
            "score": 0.73
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 14382,
            "length": 9,
            "score": 0.56
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 14774,
            "length": 9,
            "score": 0.81
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 15279,
            "length": 5,
            "score": 0.82
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 15392,
            "length": 14,
            "score": 0.71
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 15452,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 15458,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 15822,
            "length": 6,
            "score": 0.92
          },
          {
            "text": "Guha",
            "type": "Person",
            "subtype": null,
            "offset": 16406,
            "length": 4,
            "score": 0.81
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 16668,
            "length": 6,
            "score": 0.76
          },
          {
            "text": "Guha",
            "type": "Person",
            "subtype": null,
            "offset": 16676,
            "length": 4,
            "score": 0.94
          },
          {
            "text": "Guha",
            "type": "Person",
            "subtype": null,
            "offset": 16836,
            "length": 4,
            "score": 0.59
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 17094,
            "length": 10,
            "score": 0.58
          },
          {
            "text": "Guha",
            "type": "Person",
            "subtype": null,
            "offset": 17163,
            "length": 4,
            "score": 0.95
          },
          {
            "text": "Guha",
            "type": "Person",
            "subtype": null,
            "offset": 17388,
            "length": 4,
            "score": 0.97
          },
          {
            "text": "Hazard",
            "type": "Person",
            "subtype": null,
            "offset": 17440,
            "length": 6,
            "score": 0.97
          },
          {
            "text": "Singh",
            "type": "Person",
            "subtype": null,
            "offset": 17451,
            "length": 5,
            "score": 0.91
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 17558,
            "length": 5,
            "score": 0.86
          },
          {
            "text": "rater",
            "type": "PersonType",
            "subtype": null,
            "offset": 17567,
            "length": 5,
            "score": 0.62
          },
          {
            "text": "rater",
            "type": "PersonType",
            "subtype": null,
            "offset": 17663,
            "length": 5,
            "score": 0.64
          },
          {
            "text": "rater",
            "type": "PersonType",
            "subtype": null,
            "offset": 17944,
            "length": 5,
            "score": 0.62
          },
          {
            "text": "authors",
            "type": "PersonType",
            "subtype": null,
            "offset": 18031,
            "length": 7,
            "score": 0.85
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 18544,
            "length": 14,
            "score": 0.59
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 18604,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 18610,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "recently",
            "type": "DateTime",
            "subtype": null,
            "offset": 19149,
            "length": 8,
            "score": 0.8
          },
          {
            "text": "ART",
            "type": "Organization",
            "subtype": null,
            "offset": 19365,
            "length": 3,
            "score": 0.75
          },
          {
            "text": "client",
            "type": "PersonType",
            "subtype": null,
            "offset": 19413,
            "length": 6,
            "score": 0.97
          },
          {
            "text": "clients",
            "type": "PersonType",
            "subtype": null,
            "offset": 19508,
            "length": 7,
            "score": 0.96
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 19525,
            "length": 6,
            "score": 0.95
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 19715,
            "length": 6,
            "score": 0.94
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 19758,
            "length": 6,
            "score": 0.94
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 19870,
            "length": 6,
            "score": 0.8
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 19919,
            "length": 5,
            "score": 0.86
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 20139,
            "length": 5,
            "score": 0.87
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 20212,
            "length": 6,
            "score": 0.86
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 20320,
            "length": 5,
            "score": 0.77
          },
          {
            "text": "clients",
            "type": "PersonType",
            "subtype": null,
            "offset": 20454,
            "length": 7,
            "score": 0.93
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 20465,
            "length": 6,
            "score": 0.91
          },
          {
            "text": "seller",
            "type": "PersonType",
            "subtype": null,
            "offset": 21762,
            "length": 6,
            "score": 0.94
          },
          {
            "text": "seller",
            "type": "PersonType",
            "subtype": null,
            "offset": 21829,
            "length": 6,
            "score": 0.95
          },
          {
            "text": "buyers",
            "type": "PersonType",
            "subtype": null,
            "offset": 21958,
            "length": 6,
            "score": 0.75
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 21981,
            "length": 14,
            "score": 0.58
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 22041,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 22047,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "Agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 22065,
            "length": 6,
            "score": 0.63
          },
          {
            "text": "after a day",
            "type": "DateTime",
            "subtype": "Duration",
            "offset": 22114,
            "length": 11,
            "score": 0.8
          },
          {
            "text": "sellers",
            "type": "PersonType",
            "subtype": null,
            "offset": 22191,
            "length": 7,
            "score": 0.54
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 22212,
            "length": 5,
            "score": 0.71
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 22251,
            "length": 5,
            "score": 0.86
          },
          {
            "text": "seller",
            "type": "PersonType",
            "subtype": null,
            "offset": 22282,
            "length": 6,
            "score": 0.83
          },
          {
            "text": "Buyers",
            "type": "PersonType",
            "subtype": null,
            "offset": 22338,
            "length": 6,
            "score": 0.94
          },
          {
            "text": "seller",
            "type": "PersonType",
            "subtype": null,
            "offset": 22375,
            "length": 6,
            "score": 0.95
          },
          {
            "text": "seller",
            "type": "PersonType",
            "subtype": null,
            "offset": 22393,
            "length": 6,
            "score": 0.96
          },
          {
            "text": "Fourteen days",
            "type": "DateTime",
            "subtype": "Duration",
            "offset": 22459,
            "length": 13,
            "score": 0.8
          },
          {
            "text": "buyer",
            "type": "PersonType",
            "subtype": null,
            "offset": 22491,
            "length": 5,
            "score": 0.8
          },
          {
            "text": "buyer",
            "type": "PersonType",
            "subtype": null,
            "offset": 22596,
            "length": 5,
            "score": 0.91
          },
          {
            "text": "sellers",
            "type": "PersonType",
            "subtype": null,
            "offset": 22708,
            "length": 7,
            "score": 0.9
          },
          {
            "text": "buyer",
            "type": "PersonType",
            "subtype": null,
            "offset": 23182,
            "length": 5,
            "score": 0.77
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 24025,
            "length": 6,
            "score": 0.77
          },
          {
            "text": "developers",
            "type": "PersonType",
            "subtype": null,
            "offset": 24433,
            "length": 10,
            "score": 0.92
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 24949,
            "length": 6,
            "score": 0.62
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 25019,
            "length": 14,
            "score": 0.63
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 25079,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 25085,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 25214,
            "length": 5,
            "score": 0.69
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 25583,
            "length": 5,
            "score": 0.52
          },
          {
            "text": "may",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 26356,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "uploader",
            "type": "PersonType",
            "subtype": null,
            "offset": 26429,
            "length": 8,
            "score": 0.57
          },
          {
            "text": "may",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 27738,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "truster",
            "type": "PersonType",
            "subtype": null,
            "offset": 27823,
            "length": 7,
            "score": 0.89
          },
          {
            "text": "agent",
            "type": "PersonType",
            "subtype": null,
            "offset": 28091,
            "length": 5,
            "score": 0.85
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 28167,
            "length": 14,
            "score": 0.56
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 28227,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 28233,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 28789,
            "length": 6,
            "score": 0.65
          },
          {
            "text": "previously",
            "type": "DateTime",
            "subtype": null,
            "offset": 28796,
            "length": 10,
            "score": 0.8
          },
          {
            "text": "truster",
            "type": "PersonType",
            "subtype": null,
            "offset": 28822,
            "length": 7,
            "score": 0.89
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 29019,
            "length": 9,
            "score": 0.6
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 29140,
            "length": 6,
            "score": 0.58
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 29638,
            "length": 14,
            "score": 0.62
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 29698,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 29704,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 30090,
            "length": 10,
            "score": 0.71
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 30102,
            "length": 9,
            "score": 0.73
          },
          {
            "text": "Apple",
            "type": "Organization",
            "subtype": null,
            "offset": 30117,
            "length": 5,
            "score": 0.89
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 30176,
            "length": 10,
            "score": 0.82
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 30284,
            "length": 9,
            "score": 0.73
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 30423,
            "length": 9,
            "score": 0.87
          },
          {
            "text": "Aberer",
            "type": "Person",
            "subtype": null,
            "offset": 30626,
            "length": 6,
            "score": 0.91
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 30831,
            "length": 10,
            "score": 0.9
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 30870,
            "length": 6,
            "score": 0.66
          },
          {
            "text": "now",
            "type": "DateTime",
            "subtype": null,
            "offset": 31038,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 31376,
            "length": 10,
            "score": 0.8
          },
          {
            "text": "agents",
            "type": "PersonType",
            "subtype": null,
            "offset": 31411,
            "length": 6,
            "score": 0.5
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 31445,
            "length": 9,
            "score": 0.79
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 31504,
            "length": 9,
            "score": 0.87
          },
          {
            "text": "EigenTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 31573,
            "length": 10,
            "score": 0.88
          },
          {
            "text": "Appleseed",
            "type": "Organization",
            "subtype": null,
            "offset": 31588,
            "length": 9,
            "score": 0.89
          },
          {
            "text": "PeerTrust",
            "type": "Organization",
            "subtype": null,
            "offset": 31663,
            "length": 9,
            "score": 0.75
          },
          {
            "text": "Chandrasekaran",
            "type": "Person",
            "subtype": null,
            "offset": 31684,
            "length": 14,
            "score": 0.64
          },
          {
            "text": "2015",
            "type": "DateTime",
            "subtype": "DateRange",
            "offset": 31744,
            "length": 4,
            "score": 0.8
          },
          {
            "text": "2:8",
            "type": "DateTime",
            "subtype": "Time",
            "offset": 31750,
            "length": 3,
            "score": 0.8
          },
          {
            "text": "Aberer & Despotovic",
            "type": "Organization",
            "subtype": null,
            "offset": 32591,
            "length": 19,
            "score": 0.81
          },
          {
            "text": "Advogato",
            "type": "PersonType",
            "subtype": null,
            "offset": 32639,
            "length": 8,
            "score": 0.68
          }
        ]
      },
    ]
}